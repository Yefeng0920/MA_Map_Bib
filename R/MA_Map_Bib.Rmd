---
title: "Untitled"
output: html_document
date: '2023-10-06'
---


```{r global options, include=FALSE}
library(knitr)
library(rmdformats)
library(palmerpenguins)
# Global options
# options(max.print = "75")
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  tidy = TRUE,
  cache = TRUE,
  echo=TRUE)

#opts_knit$set(width = 75)

```

# Set-up

Install and load necessary libraries.

```{r load packages, cache = FALSE}
# tidy
# rm(list=ls())
# Install and load necessary library
pacman::p_load(tidyverse, 
               here,
               DT,
               ggpubr,
               readxl, 
               metafor,
               lme4,
               car,
               ggplot2,
               visdat,
               naniar,
               viridis,
               ggthemr, 
               pander,
               formatR,
               rotl,
               ape,
               ggstance,
               ggtree,
               flextable,
               bibliometrix,
               circlize,
               igraph
               )
# custom function
source(here("Function","custom.R"))
```

# Preface


# Enrichment 1: Evidence mapping

## Grid-like plots

### Data 1

```{r Data 1, warning=FALSE, echo=FALSE}
# load data
dat <- read_xlsx(here("Data","Hodkinson_2020.xlsx"))
# show data in a data
t1 <- dat %>% dfround(3) %>% DT::datatable()
t1
```


### Data wrangling

```{r}
# preprocess
dat$vi <- dat$`Std Err2`^2 
dat <- dat[, c("Intervention model", "Outcome", "Hedgesg", "vi", "Study name")]
names(dat) <- c("dimension1", "dimension2", "yi", "vi", "study_id")

# get estimate for each cell
est_dat <- dat %>% group_by(dimension1, dimension2) %>%
  group_modify(~ meta_aggregate(.x, rho = 0.5)) %>% ungroup()
```


### Visualization

```{r}
# traditional map with the number of study
est_dat$dimension1 <- as.factor(est_dat$dimension1)

Box1_map1 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_studies) ) +
  geom_point(alpha = 0.5, color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[1]) + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)") +
  #scale_size_identity() + 
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) + # scale_x_discrete(labels = function(x) str_wrap(x, width = 10), expand = expansion(mult = c(0, 0)))
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', # https://stackoverflow.com/questions/28816467/ggplot-position-legend-in-top-left
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_studies)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of studies") + # https://stackoverflow.com/questions/64701500/left-align-ggplot-caption
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(size = 12, face = "bold")) #+ coord_fixed(ratio = 1)



# traditional map with the number of effect size
Box1_map2 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_es)) +
  geom_point(alpha = 0.5, color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[3]) + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal',  
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of effect sizes") +
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))



# with effect size information
Box1_map3 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_es, color = estimate)) +
  geom_point(alpha = 0.6) + 
  scale_color_gradient(
    #name = "Mean effect",
    low = "blue",
    #mid = "blue",
    high = "red", 
    #midpoint = 0, # if using scale_fill_gradient, it only needs low and high color; if using scale_fill_gradient2, it needs mid color and midpoint
    limits = c(-1,1),
    guide = "colourbar") + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)", color = "Meta-analytic mean effect size") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of effect sizes") + 
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))


# 3-dimensional graph - we do not recommend to 3 dimensional graph because this is not that friendly to end-user
dat <- read_xlsx(here("Data","Hodkinson_2020.xlsx"))
dat$vi <- dat$`Std Err2`^2
dat <- dat[, c("Intervention model", "Outcome", "Age group", "Hedgesg", "vi", "Study name")]
names(dat) <- c("dimension1", "dimension2", "dimension3", "yi", "vi", "study_id")

# get estimate each cell 
est_dat <- dat %>% group_by(dimension1, dimension2, dimension3) %>%
  group_modify(~ meta_aggregate(.x, rho = 0.5)) %>% ungroup()

# with the third dimension
Box1_map4 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, 
                      shape = dimension3,
                      size = n_es  
                      #color = estimate
                      )) +
  geom_point(alpha = 0.6,  color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[5], aes(group = dimension3), position = position_dodge(width= 0.5)) +  #  geom_point(alpha = 0.6,  color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[5], aes(group = dimension3), position = position_dodge(width= 0.5)) +
 scale_color_gradient(
    low = "blue",
    #mid = "blue",
    high = "red", 
    limits = c(-1,1),
    guide = "colourbar") + 
  scale_shape_manual(values = c(15, 19, 17, 18, 10, 4, 3, 7, 8, 13)) +
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)", shape = "Diamension 3 (Population)") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es), group = dimension3), size = 4, color = "gray10", position = position_dodge(width = .5)) +
  labs(caption = "The value in the cell is the number of effect sizes") + 
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))


#Box1_map1 + Box1_map2 + Box1_map3 + Box1_map4 + patchwork::plot_layout(ncol = 2, nrow = 2) + patchwork::plot_annotation(tag_levels = "A")

png(filename = "Box1_map.png", width = 10, height = 10, units = "in", type = "windows", res = 400)
plot_grid(Box1_map1, Box1_map2, Box1_map3, Box1_map4, labels = c('A','B','C','D'), label_size = 14, nrow = 2, ncol = 2)
dev.off()

```


## Sankey diagrams

### Data 2

```{r Data 2, warning=FALSE, echo=FALSE}
# load data
dat <- read.csv(here("Data","Mertens_2021.csv"))
names(dat)[1] <- "publication_id"
# show data in a data
t2 <- dat %>% dfround(3) %>% DT::datatable()
t2
```


### Data wrangling

```{r}
# visualize study characteristics
dat <- dat %>%
  dplyr::select(type_experiment, intervention_technique, intervention_category, domain, population, location) 
```


### Visualization

```{r}
#png(filename = "./Box1_sankey.png", width = 6, height = 5, units = "in", type = "windows", res = 400)
ggplot(dlong(dat, type_experiment, location, population,  intervention_category, domain, intervention_technique), aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node)) +
  sankey_p(flow.alpha = 0.8,
              node.color = "transparent") +
  sankey_p_label(size = 3, color = "white", fill = "gray10", alpha = 0.6) +
  #scale_fill_viridis_d() +
  #viridis::scale_fill_viridis(discrete = T, option = "D") + 
  ggsci::scale_color_tron() + 
  theme_sankey(base_size = 10) +
  labs(x = NULL) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = .5),
        axis.text.x = element_text(color = "black", size = 9)) +
  #ggtitle("Moderator variable features") +
scale_x_discrete(labels = c("Moderator 1 \n (Experimental \n approach)", "Moderator 2 \n (Geographical \n location)", "Moderator 3 \n (Population \n characteristic)",  "Moderator 4 \n (Architecture \n category)", "Moderator 5 \n (Behavioral \n domain)", "Moderator 6 \n (Intervention \n technique)"), position = "top") %>% ggplotly()
#dev.off()



```

## Phylogenetic tree

### Data 3

```{r Data 2, warning=FALSE, echo=FALSE}
# load data
dat <- read_xlsx(here("Data","Sanders_2021.xlsx"))
# show data in a data
t3 <- dat %>% dfround(3) %>% DT::datatable()
t3
```


### Data wrangling

```{r}
dat$Species <- gsub('\\.', "_", dat$Species)

dat <- dat[!is.na(dat$Species),] # https://www.statology.org/r-remove-rows-with-na-in-one-column/

#check species we have
length(unique(dat$Species)) #184 unique species names, if no misspelling

#find Open Tree Taxonomy (OTT) IDs for each species
taxa <- tnrs_match_names(names = unique(dat$Species))

# for illustrative purpose, we just delete the species that are not matched
## find location
pos <- which(dat$Species %in% c("Phodopus_sungeroru", "Electra?__sp", "Molgula_sp", "Baetis_spp", "Agrostis_tenuis", "Anthoxanthum_odoratum", "Myotis_daubentonii","_Myotis_mystacinus","_Myotis_brandtii","_Myotis_nattereri","_Plecotus_auritus", "Pipistrellus_pipistrelles","_Pipistrellus_nathusii", "Nyctalus_nyctalus","_Nyctalus_leisleri","_Eptesicus_serotinus_", "All_families", "Pipistrellus_hesperidus/Hypsugo_anchietaia", "Myotis?_sp", "MCF7", "7288cct", "A__cristatellus_", "A__evermanni", "A__gundlachi", "A__sagrei", "bat_community_", "N__leisleri", "Poecile_sp", "Coleoptera","_Diptera","_Lepidoptera","_Erebidae","_Chironomidae","_Noctuidae_and_Psychodidae", "Nyctalus_and_Eptesicus_spp", "Anoectochilus_roxburghii", "Myotis_pilosatibialis", "Silene_latifolia"))
dat <- dat[-pos,]

# match again
taxa <- tnrs_match_names(names = unique(dat$Species)) # still some are not matched. But let's resolve it latter

# check whether occur in the synthetic tree
ott_in_tree <- ott_id(taxa)[is_in_tree(ott_id(taxa))] 
length(ott_id(taxa)) - length(is.na(ott_in_tree)) # still 10 did not appear in synthetic tree

# check which 10
out_tree <- filter(taxa, ! ott_id %in% ott_in_tree)
out_tree$search_string

dat <- dat[!dat$Species %in% c("Leptocythere_pellucida", "Myotis_daubentonii,_Myotis_mystacinus,_Myotis_brandtii,_Myotis_nattereri,_Plecotus_auritus", "Pipistrellus_pipistrelles,_Pipistrellus_nathusii", "Nyctalus_nyctalus,_Nyctalus_leisleri,_Eptesicus_serotinus_", "Myotis_lucifugus", "Acyrthosiphont", "Carabidae", "Staphylinidae", "Eptesicus_bottae", "Corethrella_spp", "P__pipistrellus", "Myotis", "Coleoptera,_Diptera,_Lepidoptera,_Erebidae,_Chironomidae,_Noctuidae_and_Psychodidae", "Pipistrellus"),]

# match again
taxa <- tnrs_match_names(names = unique(dat$Species))
#check again whether all otts occur in the synthetic tree
ott_in_tree <- ott_id(taxa)[is_in_tree(ott_id(taxa))] 
length(ott_id(taxa)) - length(is.na(ott_in_tree)) # all good

# now every ott occur in the synthesistic tree. But for the sake of brevity, we only visualize a subset of the tree
# only use studies measuring physiology
Physiology <- subset(dat, Category == "Physiology")
# remove NA
Physiology <- subset(Physiology, Species != "NA")
taxa <- tnrs_match_names(names = unique(Physiology$Species))

#make phylo tree
tree <- suppressWarnings(tol_induced_subtree(ott_ids = ott_id(taxa))) 

#the tip labels contain OTTs, which means they will not perfectly match the species names in our dataset or the taxon map that we created earlier,
#remove the extra information from the tip labels later; with the IDs removed, we can use our taxon map to replace the tip labels in the tree with the species names from dataset 
tree$tip.label <- strip_ott_ids(tree$tip.label, remove_underscores = TRUE) # https://docs.ropensci.org/rotl/reference/strip_ott_ids.html


#decapitalise species names to match with the search string names in taxa
Physiology <- Physiology %>% mutate(search_string = tolower(Species))  

#align data
Physiology <- left_join(Physiology, dplyr::select(taxa, search_string, unique_name, ott_id), by = "search_string")  

#create the variables of spp and phylo
Physiology <- Physiology %>% mutate(spp = unique_name, phylo = unique_name)

# prepare annotation data
## species-specific estimates as fixed effect
agg.es <- escalc(measure = "SMD", m1i = Experimental_Mean, m2i = Control_Mean,sd1i = Experimental_SD,sd2i = Control_SD,n1i = Experimental_N,n2i = Control_N, data = Physiology) %>% aggregate(cluster=phylo, struct="CS",rho = 0.5,addk=TRUE)
agg.es <- agg.es[c("phylo","yi","vi")]
names(agg.es) <- c("Species","Mean","SE")
agg.es <- agg.es %>% mutate(Lower_bound = Mean - sqrt(SE)*qnorm(0.975),
                      Upper_bound = Mean + sqrt(SE)*qnorm(0.975)) %>% arrange(Species)
N_obs <- Physiology %>% group_by(phylo) %>% summarise(N_obs=n()) # calculate sample size
names(N_obs)[1] <- "Species"
fe.spp.es <- left_join(agg.es,N_obs,by = "Species")
tip.label <- data.frame(Species = tree$tip.label) # extract tip label
fe.spp.es2 <- left_join(tip.label,fe.spp.es,by = "Species") 
fe.spp.es2 <- fe.spp.es2 %>% mutate(z = Mean/SE, p = pnorm(abs(z),lower.tail = F)*2)

# get class data
spp.class <- dplyr::distinct(Physiology, phylo, .keep_all = TRUE) %>% dplyr::select(Class, phylo)
names(spp.class)[2] <- "Species"
spp.class2 <- left_join(tip.label,spp.class,by = "Species")

# add spaces between genus & specific names in tree objects
#tree$tip.label <- gsub(" ","_",tree$tip.label)
#uid <- ggimage::phylopic_uid(tree$tip.label)

tree.p1 <- ggtree(tree, layout = "rectangular", cex = .4) 
tree.p2 <- tree.p1 %<+% spp.class2 + 
  geom_tiplab(aes(color  = Class),size=3,fontface = "italic",align = T, offset=0.3) +
  geom_tippoint(aes(color = Class)) + xlim_expand(c(0,21), panel = "Tree") + guides(color="none") + scale_color_viridis_d()
tree.p3 <- tree.p2 + geom_facet(panel = "Effect size", data = fe.spp.es2,
           geom = ggstance::geom_pointrangeh, # geom_pointrange
           mapping = aes(x = Mean, xmin = Lower_bound, xmax = Upper_bound, color = Class)) + 
theme_tree2() + theme(strip.background = element_rect(fill = "white"))

tree.p4 <- facet_widths(tree.p3, c(Tree=0.4,`Effect size`=0.2))

png(filename = "Box1_phylo.png", width = 6, height = 5, units = "in", type = "windows", res = 400)
tree.p4
dev.off()

```



## Missingness

### Data 1

```{r Data 1, warning=FALSE, echo=FALSE}
# load data
dat <- read_xlsx(here("Data","Hodkinson_2020.xlsx"))
# show data in a data
t1 <- dat %>% dfround(3) %>% DT::datatable()
t1
```

### Data wrangling

```{r}
# create missingness at the study level
set.seed(2023)
stdies <- sample(unique(dat$`Study name`), size = 0.2*(length(unique(dat$`Study name`))))
dat[which(dat$`Study name` %in% stdies), c("Intervention model")] <- NA

stdies <- sample(unique(dat$`Study name`), size = 0.4*(length(unique(dat$`Study name`))))
dat[which(dat$`Study name` %in% stdies), c("Comparator model")] <- NA

stdies <- sample(unique(dat$`Study name`), size = 0.25*(length(unique(dat$`Study name`))))
dat[which(dat$`Study name` %in% stdies), c("Outcome")] <- NA

stdies <- sample(unique(dat$`Study name`), size = 0.13*(length(unique(dat$`Study name`))))
dat[which(dat$`Study name` %in% stdies), c("Age group")] <- NA
```


### Visualization

```{r}
# https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html
#library(naniar)
# one way to report missness
dat2 <- dat %>%
  dplyr::select(`Intervention model`, `Comparator model`, `Outcome`, `Age group`)


dat2 %>% gg_miss_var() + theme_bw() +
  labs(x = " ", y  = "The number of missingness")

# alternative way
dat2 %>% gg_miss_fct(fct = `Intervention model`) + labs(y = "")


# visdat package also can be used  https://docs.ropensci.org/visdat/articles/using_visdat.html

vis_dat(dat2)
vis_miss(dat2)

```




# Enrichment 2: Bibliometric analysis 

## Co-authorship network

### Data 3

```{r}
# load meta-analytic data
dat <- read_xlsx(here("Data","Sanders_2021.xlsx"))
# load bibliographic data
M <- convert2df(here("Data","Sanders_2021_bib.csv"), dbsource = "scopus", format = "csv") # note that using here function does work for data wrangling
# merge data
dat.M <- left_join(M, dat, by = c("DI" = "DOI")) # DI denote DOI in bib data
```


### Data wrangling

```{r}
# construct author collaboration network
NetMatrix <- biblioNetwork(M, analysis = "collaboration",  network = "authors", sep = ";")
# visualization collaboration network
#net=networkPlot(NetMatrix,  n = 50, Title = "Author collaboration",type = "auto", size=10,size.cex=T,edgesize = 3,labelsize=1)
net_matrix <- as.matrix(NetMatrix)
diag(net_matrix) <- 0 
g <- graph_from_adjacency_matrix(net_matrix, mode = "lower", weighted = "weight")

# some quantitative analysis
# vertex and edges attributes can be accessed via the V and E functions, respectively
#we can list what vertex/edge attributes are available:
#list.vertex.attributes(g)
#list.edge.attributes(g) 
#V(g)$name[1:6]

# computing centrality measures for each vertex # https://gvegayon.github.io/appliedsnar/network-descriptive-stats.html
V(g)$indegree <-  igraph::degree(g, mode = "in")
V(g)$outdegree <- igraph::degree(g, mode = "out")
V(g)$closeness <- igraph::closeness(g, mode = "total")
V(g)$betweeness <- igraph::betweenness(g, normalized = TRUE)

# extracting each vectex features as a data.frame
stats <- as_data_frame(g, what = "vertices")

# computing quantiles for each vertex attributes 
stats_degree <- with(stats, {
 cbind(
   indegree   = quantile(indegree, c(.025, .5, .975), na.rm = TRUE),
   outdegree  = quantile(outdegree, c(.025, .5, .975), na.rm = TRUE),
   closeness  = quantile(closeness, c(.025, .5, .975), na.rm = TRUE),
   betweeness = quantile(betweeness, c(.025, .5, .975), na.rm = TRUE)
 )
})


#  compute some statistics at the graph level:
cbind(
  size    = vcount(g),
  nedges  = ecount(g),
  density = edge_density(g),
  recip   = reciprocity(g),
  centr   = centr_betw(g)$centralization,
  pathLen = mean_distance(g)
  )
```

### Visualization

```{r}
#  graph
set.seed(2023)

plot.igraph(g, 
            vertex.size = igraph::degree(g)/3,
            vertex.label = NA,
            edge.arrow.size = .25)
#gridGraphics::grid.echo()
#p1 <- grid::grid.grab()

#p1 <- grDevices::recordPlot()
#plot.new() ## clean up device
#p1 # redraw

  
wtc <- cluster_walktrap(g)
# numerically detect the network community
# modularity(wtc)
# modularity(g, membership(wtc))
member <- communities(wtc)
n_cluster <- sapply(member, length)


plot(wtc, g, 
     vertex.size = V(g)$indegree/3, # or V(g)$outdegree + 1
     vertex.label = NA,
     edge.arrow.size = .25)
#gridGraphics::grid.echo()
#grid::grid.grab()

#png(filename = "./Box2_author.png", width = 5, height = 5, units = "in", type = "windows", res = 400)
#gridExtra::grid.arrange(p1,p2)
#dev.off()


png(filename = "./Box2_author.png", width = 15, height = 15, units = "in", type = "windows", res = 400)
plot(wtc, g, 
     vertex.size = V(g)$indegree/3, # or V(g)$outdegree + 1
     vertex.label = NA,
     edge.arrow.size = .25)
dev.off()



plot(wtc, g, 
     vertex.size = E(g)$weight/5,
     vertex.label = NA,
     edge.arrow.size = .25)

# when there is a lot of isolates. Let’s try again by drawing the same plot without isolates. To do so, we need to filter the graph, for which we will use the function induced_subgraph

# which vertices are not isolates?
#which_ids <- which(degree(g, mode = "total") > 0)

# get the subgraph
#g_sub <- induced_subgraph(g, which_ids)


#plot(
#  g_sub,
#  vertex.size  = degree(g_sub)/5 +1,
#  vertex.label = NA,
#  edge.arrow.size = .25
#  )


# assign author cluster to the original data
# get the cluster membership for each author
author_membership <- membership(wtc) # attribute(author_membership)
# convert to dataframe
author_membership <- data.frame(author = names(author_membership), membership = as.numeric(author_membership))


# split the 'Authors' column into a list of authors
M_AU <- M %>% 
  separate_rows(AU, sep = ";")

# merge the author cluster information into the original data frame 'M'
AU_cluster <- M_AU %>%
  left_join(author_membership, by = c("AU" = "author")) %>%
  group_by(DI) %>%
  summarize(AU_cluster = paste(unique(membership), collapse = ";")) %>%
  ungroup()

# merge data

M.AU <- left_join(M, AU_cluster, by = c("DI" = "DI")) # DI denote DOI in bib

dat.M.AU <- left_join(dat, M.AU, by = c("DOI" = "DI"))
```

## Country collaboration network

Other sources of bibliometric-informed RoB include journal, open access, funding, etc.

```{r}
# country
M_country <- metaTagExtraction(M, Field = "AU_CO", sep = ";") 
NetMatrix <- biblioNetwork(M_country, analysis = "coupling", network = "countries", sep = ";")

net_matrix <- as.matrix(NetMatrix)
#get rid of collaboration with same country
diag(net_matrix) <- 0 
# getting rid of lower triangle
net_matrix[lower.tri(net_matrix)] <- 0 

# colnames(net_matrix) - change to title case:
colnames(net_matrix) <- str_to_title(colnames(net_matrix))
#rownames(net_matrix) - change to title case:
rownames(net_matrix) <- str_to_title(rownames(net_matrix))
#Fix "Usa" to "United States" :
colnames(net_matrix)[colnames(net_matrix) == "Usa"] <- "United States"
rownames(net_matrix)[rownames(net_matrix) == "Usa"] <- "United States"
#change "UNITED KINGDOM" to "UK" for easier plotting:
#colnames(net_matrix)[colnames(net_matrix) == "United Kingdom"] <- "UK"
#rownames(net_matrix)[rownames(net_matrix) == "United Kingdom"] <- "UK"



# color palette
color <- viridis::viridis(34, alpha = 1, #begin = 0, end = 1, 
                          option = "D")
color <- color[sample(1:34)]
# parameters # https://www.data-to-viz.com/graph/chord.html

circos.clear()
circos.par(start.degree = 90, 
           gap.degree = 3, # the gap between each country
           #track.margin = c(0.1, -0.1), 
           points.overflow.warning = FALSE)


png(filename = "Box2_country.png", width = 5, height = 5, units = "in", type = "windows", res = 400)
# base plot
chordDiagram(net_matrix, 
             grid.col = color, transparency = 0.1, 
             directional = 1,direction.type = c("arrows", "diffHeight"), diffHeight  = -0.04, annotationTrack = "grid", annotationTrackHeight = c(0.05, 0.1),link.arr.type = "big.arrow",link.sort = TRUE, link.largest.ontop = TRUE,
             preAllocateTracks = 1)
# add text and axis
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.index = get.cell.meta.data("sector.index")
  # add names to the sector. 
  circos.text(x = mean(xlim), y = ylim[1] + .01, 
              labels = sector.index, facing = "clockwise", # clockwise
              niceFacing = TRUE, cex = 0.6, adj = c(0, 0.5))
  # add graduation on axis
  circos.axis(h = "top", labels.cex = 0.01, major.tick.length = 0.01, sector.index = sector.index, track.index = 2, labels.niceFacing = T)
}, bg.border = NA)

#plot(iris$Sepal.Length)
p1 <- grDevices::recordPlot()  

#plot.new()

png(filename = "try.png", width = 12, height = 5, units = "in", type = "windows", res = 400)
plot_grid(p1,Box1_map1)
dev.off()





```






# Enrichment 3: Altmetric analyses


Errington T M, Mathur M, Soderberg C K, et al. Investigating the replicability of preclinical cancer biology[J]. Elife, 2021, 10: e71601.

https://osf.io/e5nvr/

```{r}
# load meta-analytic data
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv")))  

altmetric.crawler <- list(NULL)
for (n in 1:length(dat$DOI)) {
  # JASON formate
  altmetric.crawler[[n]] <- try(list(format.Altmetric(getAltmetrics(doi = dat$DOI[n]))),silent=TRUE) }

# get lists within lists
altmetric.crawler2 <- sapply(altmetric.crawler, function(x) {x})
# retrieve stats
altmetrics <- altmetric_summary(altmetric.crawler2) 

#save(data, file = "data.Rdata")
#write.csv(altmetrics,file = "Data/altmetrics.csv")

altmetrics <- read.csv(file = "Data/altmetrics.csv")


altmetrics2 <- altmetrics %>% distinct(paper, .keep_all = TRUE)
altmetrics2 <- altmetrics2 %>% mutate(count = Policy + Patent)

altmetrics2 <- altmetrics2 %>% mutate(group = rep("",nrow(altmetrics2)))


png(filename = "Box3_altmetric1.png", width = 5, height = 3, units = "in", type = "windows", res = 400)
Box3_altmetric1 <- ggplot2::ggplot() + ggbeeswarm::geom_quasirandom(data = altmetrics2, ggplot2::aes(y = Altmetric.score, x = group, size = count), fill = "#1B9E77", col="#999999", alpha=0.8, shape = 21) + 
  ylim(0,300) +
  ggplot2::coord_flip() +
      ggplot2::theme_bw() +
      ggplot2::guides(fill = "none", colour = "none") +
      ggplot2::theme(legend.position= c(0, 1), legend.justification = c(0, 1)) +
      ggplot2::theme(legend.title = ggplot2::element_text(size = 9)) +
      ggplot2::theme(legend.direction="horizontal") +
      ggplot2::theme(legend.background = ggplot2::element_blank()) +
      ggplot2::labs(x = "Social media interest", y = "Altmetric score", size = latex2exp::TeX("Policy and patent citations")) +
      #ggplot2::theme(axis.ticks.y = element_blank()) + 
      ggplot2::theme(axis.text.y = ggplot2::element_text(size = 10, colour ="black",hjust = 0.5, angle = 0))
dev.off()



# add altmetrics and transnational info to an evidence map 
# load meta-analytic data
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv"))) 
altmetrics <- read.csv(file = "Data/altmetrics.csv")

# add altemtrics to the original data
dat <- dat %>% mutate(Altmetric.score = altmetrics$Altmetric.score, policy = altmetrics$Policy, patent = altmetrics$Patent)

dat <- dat[, c("Original paper journal", "Replication study fully completed", "Altmetric.score", "Paper #")]
names(dat) <- c("dimension1", "dimension2", "score", "study_id")
dat$score <- round(dat$score,0)

# delete the cases where the replications have not be conducted due to the lack of experimental protocol details
dat <- dat[!dat$dimension2 == "Not applicable",]


# run altmetric_aggregate function through each combination 
est_dat <- 
  dat %>%
  group_by(dimension1, dimension2) %>%
  group_modify(~ altmetric_aggregate(.x)) %>%
  ungroup()

est_dat1 <- est_dat


# policy and patent counts
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv")))

# add altemtrics to the original data
dat <- dat %>% mutate(Altmetric.score = altmetrics$Altmetric.score, policy = altmetrics$Policy, patent = altmetrics$Patent)
dat <- dat %>% mutate(count = patent + policy)

dat <- dat[, c("Original paper journal", "Replication study fully completed", "count", "Paper #")]
names(dat) <- c("dimension1", "dimension2", "count", "study_id")
dat$count <- round(dat$count,0)

# delete the cases where the replications have not be conducted due to the lack of experimental protocol details
dat <- dat[!dat$dimension2 == "Not applicable",]


# run translation_aggregate function through each cell 
est_dat <- 
  dat %>%
  group_by(dimension1, dimension2) %>%
  group_modify(~ translation_aggregate(.x)) %>%
  ungroup()

est_dat2 <- est_dat


colnames(est_dat2)[colnames(est_dat2) == "estimate"] <- "count"
est_dat2 <- est_dat2[,1:3]

# combine
est_dat <- merge(est_dat1, est_dat2, by = c("dimension1", "dimension2"))

est_dat$count <- round(est_dat$count,1)

est_dat <- est_dat %>% mutate(dimension2 = case_when(dimension2 == "No replication"  ~ "Incomplete replication",
                                             dimension2 == "Full replication"  ~ "Full replication",
                                             dimension2 == "Partial replication"  ~ "Partial replication"))


png(filename = "Box3_altmetric2.png", width = 6, height = 6, units = "in", type = "windows", res = 400)
Box3_altmetric2 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = count, color = estimate)) +
  geom_point(alpha = 0.6) + 
  scale_color_gradient(
    low = "#E6AB02",
    #mid = "blue",
    high = "purple", 
    #midpoint = 0, # if using scale_fill_gradient, it only needs low and high color; if using scale_fill_gradient2, it needs mid color and midpoint
    limits = c(0,400),
    guide = "colourbar") + 
  labs(x = "Dimension 1 (Journal)", y = " Dimension 2 (Replication completion)", color = "Altmetric score") +
  scale_size_identity() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', # https://stackoverflow.com/questions/28816467/ggplot-position-legend-in-top-left
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(count)), size = 2.5, color = "gray10", fontface = "bold") +
  labs(caption = "The value in the cell is the citation count of policies and patents") +
   theme(plot.caption = element_text(size = 8, color = "gray10", face = "italic"))
dev.off()


png(filename = "Box3_altmetric.png", width = 5, height = 7, units = "in", type = "windows", res = 400)
plot_grid(Box3_altmetric1, Box3_altmetric2, labels = c('A','B'), label_size = 14, nrow = 2, ncol = 1, rel_heights = c(1,2)) # https://beep-boopr.github.io/ubcBIOL548L/articles/group-03_Using-cowplot-multi-panel.html
dev.off()
```



# other bubble plot
```{r}
#----------------------------------------

# stretched contingency table
with(dat_Hodkinson_2020,ftable(`Intervention model`,Outcome)) %>% data.frame() -> dat
# alternatively
# with(dat,table(Randomisation_animal,Species_diurnal_nocturnal,grouped_tissue,Daytime_or_nighttime_melatonin)) %>% as.data.frame()

names(dat) <- c("Intervention","Outcome","Freq")
png(filename = "Ballon plot.png", width = 6, height = 4, units = "in", type = "windows", res = 400)
Ballon_plot <- ggballoonplot(dat, x = reorder("Intervention", "Freq"), y = "Outcome", size = "Freq", fill = "Freq", 
 #facet.by = c("Study_design"),
 ggtheme = theme_bw()) +
 scale_fill_continuous(type = "gradient") + #https://ggplot2.tidyverse.org/reference/scale_colour_continuous.html#:~:text=The%20scales%20scale_colour_continuous%20%28%29%20and%20scale_fill_continuous%20%28%29%20are,mapped%20onto%20the%20colour%20or%20fill%20aesthetics%2C%20respectively.
 #scale_fill_gradientn(colors = c("#0D0887FF")) +
 guides(fill = "none") + 
 labs(size = "Sample size") + 
 theme(strip.background = element_rect(fill = "white"))
Ballon_plot
dev.off()






library(vcd)
with(dat,ftable(dimension1,dimension2,exclude = c(NA, NaN))) -> data2

png(filename = "mosaic.png", width = 4, height = 8, units = "in", type = "windows", res = 400)
structable(dimension1 ~ dimension2, data=data2) %>% vcd::mosaic(shade = TRUE, legend = F, direction = "h")
dev.off()

# equivalent
# mosaic(~ Light_colour + Species_diurnal_nocturnal + grouped_tissue, data = data2,shade = TRUE,legend = F)
```







```{r}
# fix obviously wrong names 
# tabyl(dat, Location)
dat2 <- dat
dat2$Location[dat2$Location == "Indian"] <- "India"
dat2$Location[dat2$Location == "Radolfzell"] <- "Germany"
dat2$Location[dat2$Location == "Skrylle Nature Reserve"] <- "Sweden"
dat2$Location[dat2$Location == "Suruga Bay, Shizuoka Prefecture, Japan"] <- "Japan"
dat2$Location[dat2$Location == "Varanasi"] <- "India"

#https://www.riinu.me/2022/02/world-map-ggplot2/
# map data
world_map <- map_data("world") %>% 
  filter(! long > 180) #remove countries with longitude >180 to make equal projection-like map without artifacts
#table(world_map$region) #note that United Kingdom is UK here

# check matching
dat2$Location[!(dat2$Location %in% world_map$region)]
# fix America to USA
dat2$Location[dat2$Location == "America"] <- "USA"

# check again
dat2$Location[!(dat2$Location %in% world_map$region)] # mising data are fine

# extract the number of species and the number of effect sizes in each country
dat2 %>% group_by(Location) %>% 
  summarise(n_species = length(unique(Phy)),
            n_effects = n()) %>% ungroup %>% filter(!is.na(Location)) -> country_n

country_n <- country_n %>% mutate(region = Location)

## colour all regions on the map
#emptymap <- tibble(region = unique(world_map$region),n = rep(0,length(unique(world_map$region)))) #create table with all counts as 0
#create table with all counts as 0
emptymap <- distinct(world_map,region, .keep_all = T) %>% mutate(n = 0) 
#join with actual counts table

fullmap <- left_join(emptymap, country_n, by = "region") 
# make new column for fixed counts
fullmap$n_species2 <- fullmap$n + fullmap$n_species
fullmap$n_effects2 <- fullmap$n + fullmap$n_effects 
# change NA to 0 for regions with no counts
fullmap$n_species2[is.na(fullmap$n_species2)] <- 0 
fullmap$n_effects2[is.na(fullmap$n_effects2)] <- 0 

# https://datavizpyr.com/how-to-make-world-map-with-ggplot2-in-r/
png(filename = "map_effect_size.png", width = 5, height = 3, units = "in", type = "windows", res = 400)
fullmap %>% 
  ggplot(aes(fill = n_effects2, map_id = region)) +
  geom_map(map = world_map) +
  expand_limits(x = world_map$long, y = world_map$lat) +
  #coord_map("moll") +
  theme_map(line_size = 0.5) + 
  theme(legend.position="right") +
  scale_fill_gradient(low = "lightgray", high = "#D53E4F", limits = c(0, 120),guide = guide_colorbar(direction = "vertical.")) +
  guides(fill = guide_colourbar(barwidth = unit(15, units = "mm"), barheight = unit(20, units = "mm"))) +
  labs(fill = "effect size") 
dev.off()


```






