---
title: 'Enrichment analyses of meta-analyses: evidence mapping, bibliometrics, and  alternative  impact  metrics'
subtitle: "Visualizing study characteristics, hidden risk of bias, societal influence, and research translation"
author: "Yefeng Yang, Malgorzata Lagisz, Shinichi Nakagawa"
output:
  rmdformats::robobook:
    code_folding: show #hide
    self_contained: true
    thumbnails: false
    lightbox: true
pkgdown:
  as_is: true
bibliography: references.bib
csl: science.csl
---

# Contributors

Yefeng Yang, Malgorzata Lagisz, Shinichi Nakagawa

# Update

Last update Dec. 2023

# Preface

The R script provided with this `html` reproduces all the figures in the main text. For the explanation of each figure, see the main text. Version information of each package used in this `html` is listed at the end. The relevant GitHub repository can be found at `https://github.com/Yefeng0920/MA_Map_Bib`. 

# Citation

If our paper and `R script` have helped you, please cite the following paper:

> Yefeng Yang, Malgorzata Lagisz, Shinichi Nakagawa. Enriching meta-analyses through scoping review, bibliometrics, and alternative impact metrics: Visualizing study characteristics, hidden risk of bias, societal influence, and research translation. arXiv, 2023. 

# Contact

If you have any questions, mistakes, or bug to report, please contact corresponding authors:

- Dr. Yefeng Yang

Evolution & Ecology Research Centre, EERC
School of Biological, Earth and Environmental Sciences, BEES
The University of New South Wales, Sydney, Australia

Email: yefeng.yang1@unsw.edu.au

- Professor Shinichi Nakagawa, PhD, FRSN

Evolution & Ecology Research Centre, EERC
School of Biological, Earth and Environmental Sciences, BEES
The University of New South Wales, Sydney, Australia

Email: s.nakagawa@unsw.edu.au

# Set-up

Setting global options will apply those options to all of the following chunks of code in the tutorial.

```{r global options, include=FALSE}
# Global options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  tidy = TRUE,
  cache = TRUE,
  echo=TRUE)
```

Our illustrations use R statistical software and existing R packages, which you will first need to download and install.

If you do not have it on your machine, first install `R` ([download](https://cran.r-project.org/)). We recommend also downloading `RStudio`, a popular integrated development environment for coding with `R`, created by a company named posit ([download](https://posit.co/products/open-source/rstudio/)). 

After installing `R`, you must install several packages that contain necessary functions for performing the analyses in this tutorial. If the packages are archived in CRAN, use `install.packages()` to install them. To install packages that are not on CRAN and archived in Github repositories, execute `devtools::install_github()`.

The package list is as follows:

`tidyverse`, `here`, `DT`, `ggpubr`, `readxl`, `metafor`, `lme4`, `car`,  `ggplot2`, `cowplot`, `visdat`, `naniar`, `viridis`, `ggthemr`, `pander`, `formatR`, `rotl`, `ape`, `ggstance`, `ggtree`, `flextable`, `bibliometrix`, `circlize`, `igraph`.

```{r packages, cache = FALSE, echo = T}
# tidy
# rm(list=ls())
# Install and load necessary library
pacman::p_load(knitr,
               rmdformats,
               tidyverse, 
               here,
               DT,
               ggpubr,
               readxl, 
               metafor,
               lme4,
               car,
               ggplot2,
               viridis,
               ggthemr, 
               pander,
               formatR,
               rotl,
               cowplot,
               ape,
               ggstance,
               ggtree,
               flextable,
               bibliometrix,
               circlize,
               igraph
               )
```

# Custom function

We provide helper functions necessary for our illustrations. You can load these custom functions from the `.R file` in **Function** sub-directory using the source function and the code provided below. Alternatively, you can copy and paste the code of these functions into your console and execute the code them to load functions into your computer's working memory.

```{r function, warning = FALSE, echo = TRUE}
# custom function
source(here("Function","custom.R"))
```

# Enrichment 1: Evidence mapping 

The first enrichment analysis is evidence mapping (sometimes termed scoping review, evidence review). It contains three types of plots: (1) **grid-like plots (Figure I)**, (2) __Sankey diagrams (Figure II)__, and (3) __phylogenetic trees (Figure III)__.

## Grid-like plots 

We use `Data 1` in the main text to illustrate how to make the grid-like plots (Figure I). `Data 1` was originally collected by Hodkinson et al. @hodkinson2020self, who conducted a network meta-analysis to assess the efficacy of different self-management interventions (multidisciplinary case management, regularly supported self-management, and minimally supported self-management) in enhancing the quality of life among asthma patients. Note that the following `R code` was adapted from @polanin2023evidence.

### Data 1

```{r data1, warning = FALSE, echo = TRUE}
# load data
dat <- read_xlsx(here("Data","Hodkinson_2020.xlsx"))

# preprocess
dat$vi <- dat$`Std Err2`^2 
dat <- dat[, c("Intervention model", "Outcome", "Hedgesg", "vi", "Study name")]
names(dat) <- c("dimension1", "dimension2", "yi", "vi", "study_id")

# show data in a datatable
t1 <- dat %>% dfround(3) %>% DT::datatable()
t1
```

### Visualization

Figure I shown in the main text can be made with:

```{r Figure I, warning = FALSE, echo = TRUE, fig.height=10, fig.width=10}
# get estimate for each cell
est_dat <- dat %>% group_by(dimension1, dimension2) %>%
  group_modify(~ meta_aggregate(.x, rho = 0.5)) %>% ungroup()

# traditional map with the number of study
est_dat$dimension1 <- as.factor(est_dat$dimension1)

Box1_map1 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_studies) ) +
  geom_point(alpha = 0.5, color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[1]) + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) + # 
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_studies)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of studies") + 
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(size = 12, face = "bold")) 


# traditional map with the number of effect size
Box1_map2 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_es)) +
  geom_point(alpha = 0.5, color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[3]) + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal',  
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of effect sizes") +
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))



# with effect size information
Box1_map3 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = n_es, color = estimate)) +
  geom_point(alpha = 0.6) + 
  scale_color_gradient(
    low = "blue",
    high = "red", 
    limits = c(-1,1),
    guide = "colourbar") + 
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)", color = "Meta-analytic mean effect size") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es)), size = 4, color = "gray10") +
  labs(caption = "The value in the cell is the number of effect sizes") + 
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))


# 3-dimensional graph - we do not recommend to 3 dimensional graph because this is not that friendly to end-user
dat <- read_xlsx(here("Data","Hodkinson_2020.xlsx"))
dat$vi <- dat$`Std Err2`^2
dat <- dat[, c("Intervention model", "Outcome", "Age group", "Hedgesg", "vi", "Study name")]
names(dat) <- c("dimension1", "dimension2", "dimension3", "yi", "vi", "study_id")

# get estimate each cell 
est_dat <- dat %>% group_by(dimension1, dimension2, dimension3) %>%
  group_modify(~ meta_aggregate(.x, rho = 0.5)) %>% ungroup()

# with the third dimension
Box1_map4 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, 
                      shape = dimension3,
                      size = n_es  
                      )) +
  geom_point(alpha = 0.6,  color = RColorBrewer::brewer.pal(n = 8, name = "Dark2")[5], aes(group = dimension3), position = position_dodge(width= 0.5)) +
 scale_color_gradient(
    low = "blue",
    high = "red", 
    limits = c(-1,1),
    guide = "colourbar") + 
  scale_shape_manual(values = c(15, 19, 17, 18, 10, 4, 3, 7, 8, 13)) +
  labs(x = "Dimension 1 (Intervention)", y = "Dimension 2 (Outcome)", shape = "Diamension 3 (Population)") +
  scale_size(range=c(5,10)) +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(n_es), group = dimension3), size = 4, color = "gray10", position = position_dodge(width = .5)) +
  labs(caption = "The value in the cell is the number of effect sizes") + 
   theme(plot.caption = element_text(size = 10, color = "gray10", face = "italic"),
         axis.text = element_text(size = 12),
         axis.title = element_text(face = "bold", size = 12))


#Box1_map1 + Box1_map2 + Box1_map3 + Box1_map4 + patchwork::plot_layout(ncol = 2, nrow = 2) + patchwork::plot_annotation(tag_levels = "A")
#png(filename = "Box1_map.png", width = 10, height = 10, units = "in", type = "windows", res = 400)
plot_grid(Box1_map1, Box1_map2, Box1_map3, Box1_map4, labels = c('A','B','C','D'), label_size = 14, nrow = 2, ncol = 2)
```

## Sankey diagrams 

We used `Data 2` in the main text to illustrate how to make the Sankey diagrams (Figure II). `Data 2` was originally collected by Mertens et al. @mertens2022effectiveness ,who employed a multilevel meta-analytic model to synthesize evidence on the effectiveness of choice architecture interventions (often referred to as nudges) for behaviour change across various techniques, behavioural domains, and other study characteristics (e.g., populations and locations). The core `R code` came from `https://github.com/davidsjoberg/ggsankey/blob/main/R/sankey.R`.  

### Data 2

```{r data2, warning = FALSE, echo = TRUE}
# load data
dat <- read.csv(here("Data","Mertens_2021.csv"))
names(dat)[1] <- "publication_id"
# show data in a data
t2 <- dat %>% dfround(3) %>% DT::datatable()
t2
```

### Visualization

Figure II can be made with:

```{r Figure II, warning = FALSE, echo = TRUE}
# pre-process
dat <- dat %>%
  dplyr::select(type_experiment, intervention_technique, intervention_category, domain, population, location) 

#png(filename = "./Box1_sankey.png", width = 6, height = 5, units = "in", type = "windows", res = 400)
ggplot(dlong(dat, type_experiment, location, population,  intervention_category, domain, intervention_technique), aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node)) +
  sankey_p(flow.alpha = 0.8,
              node.color = "transparent") +
  sankey_p_label(size = 3, color = "white", fill = "gray10", alpha = 0.6) +
  ggsci::scale_color_tron() + 
  theme_sankey(base_size = 10) +
  labs(x = NULL) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = .5),
        axis.text.x = element_text(color = "black", size = 9)) +
scale_x_discrete(labels = c("Moderator 1 \n (Experimental \n approach)", "Moderator 2 \n (Geographical \n location)", "Moderator 3 \n (Population \n characteristic)",  "Moderator 4 \n (Architecture \n category)", "Moderator 5 \n (Behavioral \n domain)", "Moderator 6 \n (Intervention \n technique)"), position = "top") 
```

## Phylogenetic trees

We used `Data 3` in the main text to illustrate how to make the phylogenetic trees (Figure III). `Data 3` was originally collected by Sanders  et al. @sanders2021meta , who used a Bayesian meta-analytic model to synthesize evidence regarding the impacts of artificial light at night on physiological, phenological, life history, activity patterns, and population/community-based outcomes. This meta-analysis included more than 180 species. We only used the physiological outcomes.

### Data 3

```{r data3, warning = FALSE, echo = TRUE}
# load data
dat <- read_xlsx(here("Data","Sanders_2021.xlsx"))
# show data in a data
t3 <- dat %>% dfround(3) %>% DT::datatable()
t3
```

### Visualization

Figure III can be made with:

```{r Figure III, warning = FALSE, echo = TRUE}
# some data wrangling
dat$Species <- gsub('\\.', "_", dat$Species)
dat <- dat[!is.na(dat$Species),] # 

#check species we have
#length(unique(dat$Species)) #184 unique species names, if no misspelling

#find Open Tree Taxonomy (OTT) IDs for each species
taxa <- tnrs_match_names(names = unique(dat$Species))

# for illustrative purpose, we just delete the species that are not matched
## find location
pos <- which(dat$Species %in% c("Phodopus_sungeroru", "Electra?__sp", "Molgula_sp", "Baetis_spp", "Agrostis_tenuis", "Anthoxanthum_odoratum", "Myotis_daubentonii","_Myotis_mystacinus","_Myotis_brandtii","_Myotis_nattereri","_Plecotus_auritus", "Pipistrellus_pipistrelles","_Pipistrellus_nathusii", "Nyctalus_nyctalus","_Nyctalus_leisleri","_Eptesicus_serotinus_", "All_families", "Pipistrellus_hesperidus/Hypsugo_anchietaia", "Myotis?_sp", "MCF7", "7288cct", "A__cristatellus_", "A__evermanni", "A__gundlachi", "A__sagrei", "bat_community_", "N__leisleri", "Poecile_sp", "Coleoptera","_Diptera","_Lepidoptera","_Erebidae","_Chironomidae","_Noctuidae_and_Psychodidae", "Nyctalus_and_Eptesicus_spp", "Anoectochilus_roxburghii", "Myotis_pilosatibialis", "Silene_latifolia"))
dat <- dat[-pos,]

# match again
taxa <- tnrs_match_names(names = unique(dat$Species)) # still some are not matched. But let's resolve it latter

# check whether occur in the synthetic tree
ott_in_tree <- ott_id(taxa)[is_in_tree(ott_id(taxa))] 
#length(ott_id(taxa)) - length(is.na(ott_in_tree)) # still 10 did not appear in synthetic tree

# check which 10
out_tree <- filter(taxa, ! ott_id %in% ott_in_tree)
#out_tree$search_string

dat <- dat[!dat$Species %in% c("Leptocythere_pellucida", "Myotis_daubentonii,_Myotis_mystacinus,_Myotis_brandtii,_Myotis_nattereri,_Plecotus_auritus", "Pipistrellus_pipistrelles,_Pipistrellus_nathusii", "Nyctalus_nyctalus,_Nyctalus_leisleri,_Eptesicus_serotinus_", "Myotis_lucifugus", "Acyrthosiphont", "Carabidae", "Staphylinidae", "Eptesicus_bottae", "Corethrella_spp", "P__pipistrellus", "Myotis", "Coleoptera,_Diptera,_Lepidoptera,_Erebidae,_Chironomidae,_Noctuidae_and_Psychodidae", "Pipistrellus"),]

# match again
taxa <- tnrs_match_names(names = unique(dat$Species))
#check again whether all otts occur in the synthetic tree
ott_in_tree <- ott_id(taxa)[is_in_tree(ott_id(taxa))] 
#length(ott_id(taxa)) - length(is.na(ott_in_tree)) # all good

# now every ott occur in the synthesistic tree. But for the sake of brevity, we only visualize a subset of the tree
# only use studies measuring physiology
Physiology <- subset(dat, Category == "Physiology")
# remove NA
Physiology <- subset(Physiology, Species != "NA")
taxa <- tnrs_match_names(names = unique(Physiology$Species))

#make phylo tree
tree <- suppressWarnings(tol_induced_subtree(ott_ids = ott_id(taxa))) 

#the tip labels contain OTTs, which means they will not perfectly match the species names in our dataset or the taxon map that we created earlier,
#remove the extra information from the tip labels later; with the IDs removed, we can use our taxon map to replace the tip labels in the tree with the species names from dataset 
tree$tip.label <- strip_ott_ids(tree$tip.label, remove_underscores = TRUE) 

#decapitalise species names to match with the search string names in taxa
Physiology <- Physiology %>% mutate(search_string = tolower(Species))  

#align data
Physiology <- left_join(Physiology, dplyr::select(taxa, search_string, unique_name, ott_id), by = "search_string")  

#create the variables of spp and phylo
Physiology <- Physiology %>% mutate(spp = unique_name, phylo = unique_name)

# prepare annotation data
## species-specific estimates as fixed effect
agg.es <- escalc(measure = "SMD", m1i = Experimental_Mean, m2i = Control_Mean,sd1i = Experimental_SD,sd2i = Control_SD,n1i = Experimental_N,n2i = Control_N, data = Physiology) %>% aggregate(cluster=phylo, struct="CS",rho = 0.5,addk=TRUE)
agg.es <- agg.es[c("phylo","yi","vi")]
names(agg.es) <- c("Species","Mean","SE")
agg.es <- agg.es %>% mutate(Lower_bound = Mean - sqrt(SE)*qnorm(0.975),
                      Upper_bound = Mean + sqrt(SE)*qnorm(0.975)) %>% arrange(Species)
N_obs <- Physiology %>% group_by(phylo) %>% summarise(N_obs=n()) # calculate sample size
names(N_obs)[1] <- "Species"
fe.spp.es <- left_join(agg.es,N_obs,by = "Species")
tip.label <- data.frame(Species = tree$tip.label) # extract tip label
fe.spp.es2 <- left_join(tip.label,fe.spp.es,by = "Species") 
fe.spp.es2 <- fe.spp.es2 %>% mutate(z = Mean/SE, p = pnorm(abs(z),lower.tail = F)*2)

# get class data
spp.class <- dplyr::distinct(Physiology, phylo, .keep_all = TRUE) %>% dplyr::select(Class, phylo)
names(spp.class)[2] <- "Species"
spp.class2 <- left_join(tip.label,spp.class,by = "Species")

# make each panel
tree.p1 <- ggtree(tree, layout = "rectangular", cex = .4) 
tree.p2 <- tree.p1 %<+% spp.class2 + 
  geom_tiplab(aes(color  = Class),size=3,fontface = "italic",align = T, offset=0.3) +
  geom_tippoint(aes(color = Class)) + xlim_expand(c(0,21), panel = "Tree") + guides(color="none") + scale_color_viridis_d()
tree.p3 <- tree.p2 + geom_facet(panel = "Effect size", data = fe.spp.es2,
           geom = ggstance::geom_pointrangeh, 
           mapping = aes(x = Mean, xmin = Lower_bound, xmax = Upper_bound, color = Class)) + 
  theme_tree2() + theme(strip.background = element_rect(fill = "white"))

#png(filename = "Box1_phylo.png", width = 6, height = 5, units = "in", type = "windows", res = 400)
facet_widths(tree.p3, c(Tree=0.4,`Effect size`=0.2))
```

# Enrichment 2: Bibliometric analysis

The second enrichment analysis is bibliometric anlaysis. It can produce two main graphs: (1) __Co-authorship network (Figure IV)__, and (2) __Country network (Figure V)__.

## Co-authorship network

We use the bibliometric data associated with `Data 3` to illustrate the construction of co-authorship network (Figure IV) in meta-analytic evidence base. The figure was inspired by Moulin, et al. @moulin2020using, who originally implemented it using Matlab and VOSviewer.

### Data 3

```{r bib.data3, warning = FALSE, message = FALSE, echo = TRUE}
# load data
dat <- read_xlsx(here("Data","Sanders_2021.xlsx"))
# load bibliographic data
M <- convert2df(here("Data","Sanders_2021_bib.csv"), dbsource = "scopus", format = "csv") %>% suppressMessages() # note that using here function does work for data wrangling
# merge data
dat.M <- left_join(M, dat, by = c("DI" = "DOI")) # DI denote DOI in bib data
```


### Visualization

Figure IV can be made with:

```{r Figure IV, warning = FALSE, echo = TRUE, fig.height=10, fig.width=10}
# construct author collaboration network
NetMatrix <- biblioNetwork(M, analysis = "collaboration",  network = "authors", sep = ";")
net_matrix <- as.matrix(NetMatrix)
diag(net_matrix) <- 0 
g <- graph_from_adjacency_matrix(net_matrix, mode = "lower", weighted = "weight")
# computing centrality measures for each vertex 
V(g)$indegree <-  igraph::degree(g, mode = "in")
V(g)$outdegree <- igraph::degree(g, mode = "out")
V(g)$closeness <- igraph::closeness(g, mode = "total")
V(g)$betweeness <- igraph::betweenness(g, normalized = TRUE)

#  graph
set.seed(2023)
# using random walks to detect the network community
wtc <- cluster_walktrap(g)
# modularity(wtc)
# modularity(g, membership(wtc))
# member <- communities(wtc)
# n_cluster <- sapply(member, length)

#png(filename = "./Box2_author.png", width = 15, height = 15, units = "in", type = "windows", res = 400)
plot(wtc, g, 
     vertex.size = V(g)$indegree/3, # or V(g)$outdegree + 1
     vertex.label = NA,
     edge.arrow.size = .25)
```

Besides the visualization, we also can do some quantitative analysis:

```{r computation, warning = FALSE, echo = TRUE}
# extracting each vectex features as a data.frame
stats <- as_data_frame(g, what = "vertices")

# computing quantiles for each vertex attributes 
stats_degree <- with(stats, {
 cbind(
   indegree   = quantile(indegree, c(.025, .5, .975), na.rm = TRUE),
   outdegree  = quantile(outdegree, c(.025, .5, .975), na.rm = TRUE),
   closeness  = quantile(closeness, c(.025, .5, .975), na.rm = TRUE),
   betweeness = quantile(betweeness, c(.025, .5, .975), na.rm = TRUE)
 )
})

# compute some statistics at the graph level:
cbind(
  size    = vcount(g),
  nedges  = ecount(g),
  density = edge_density(g),
  recip   = reciprocity(g),
  centr   = centr_betw(g)$centralization,
  pathLen = mean_distance(g)
  )
```


## Country network

The same bibliometric data can be to illustrate the construction of country network (Figure V) in meta-analytic evidence base.

### Data 3

```{r bib2.data3, warning = FALSE, message = FALSE, echo = TRUE, fig.height=12, fig.width=12}
# country
M_country <- metaTagExtraction(M, Field = "AU_CO", sep = ";") 
NetMatrix <- biblioNetwork(M_country, analysis = "coupling", network = "countries", sep = ";")

net_matrix <- as.matrix(NetMatrix)
#get rid of collaboration with same country
diag(net_matrix) <- 0 
# getting rid of lower triangle
net_matrix[lower.tri(net_matrix)] <- 0 

# colnames(net_matrix) - change to title case:
colnames(net_matrix) <- str_to_title(colnames(net_matrix))
#rownames(net_matrix) - change to title case:
rownames(net_matrix) <- str_to_title(rownames(net_matrix))
#Fix "Usa" to "United States" :
colnames(net_matrix)[colnames(net_matrix) == "Usa"] <- "United States"
rownames(net_matrix)[rownames(net_matrix) == "Usa"] <- "United States"
```

### Visualization

Figure V can be made with:

```{r Figure V, warning = FALSE, echo = TRUE, fig.height=7, fig.width=7}
# color palette
color <- viridis::viridis(34, alpha = 1, option = "D")
color <- color[sample(1:34)] 

circos.clear()
circos.par(start.degree = 90, 
           gap.degree = 3,  
           points.overflow.warning = FALSE)

#png(filename = "Box2_country.png", width = 5, height = 5, units = "in", type = "windows", res = 400)
chordDiagram(net_matrix, 
             grid.col = color, transparency = 0.1, 
             directional = 1,direction.type = c("arrows", "diffHeight"), diffHeight  = -0.04, annotationTrack = "grid", annotationTrackHeight = c(0.05, 0.1),link.arr.type = "big.arrow",link.sort = TRUE, link.largest.ontop = TRUE,
             preAllocateTracks = 1)
# add text and axis
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.index = get.cell.meta.data("sector.index")
  # add names to the sector. 
  circos.text(x = mean(xlim), y = ylim[1] + .01, 
              labels = sector.index, facing = "clockwise", # clockwise
              niceFacing = TRUE, cex = 0.6, adj = c(0, 0.5))
  # add graduation on axis
  circos.axis(h = "top", labels.cex = 0.01, major.tick.length = 0.01, sector.index = sector.index, track.index = 2, labels.niceFacing = T)
}, bg.border = NA)
```

# Enrichment 3: Altmetric analyses 

We used `Data 4` in the main text to illustrate how to visualize the  alternative impact metrics (Figure VI). `Data 4` was originally used to examine the replicability of the preclinical cancer biology @errington2021investigating.

## Data 4

```{r data4, warning = FALSE, message = FALSE, echo = TRUE}
# load meta-analytic data
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv")))  
# use a custom function to extract data using API
# because it takes a while to extract data using API, we just upload the pre-extracted data.
altmetrics <- read.csv(here("Data","altmetrics.csv"))
#-------------------not run-------------------#
#altmetric.crawler <- list(NULL)
#for (n in 1:length(dat$DOI)) {
#  # JASON format
#  altmetric.crawler[[n]] <- try(list(format.Altmetric(getAltmetrics(doi = dat$DOI[n]))),silent=TRUE) }

# get lists within lists
#altmetric.crawler2 <- sapply(altmetric.crawler, function(x) {x})
# retrieve stats
#altmetrics <- altmetric_summary(altmetric.crawler2) 
#save(data, file = "data.Rdata")
#write.csv(altmetrics,file = "Data/altmetrics.csv")
#-------------------not run-------------------#
# show data in a datatable
t4 <- altmetrics %>% DT::datatable()
t4
```

## Visualization

Figure VI can be made with: 

```{r Figure VI, warning = FALSE, message = FALSE, echo = TRUE, fig.height=8, fig.width=8}
altmetrics2 <- altmetrics %>% distinct(paper, .keep_all = TRUE)
altmetrics2 <- altmetrics2 %>% mutate(count = Policy + Patent)
altmetrics2 <- altmetrics2 %>% mutate(group = rep("",nrow(altmetrics2)))

#png(filename = "Box3_altmetric1.png", width = 5, height = 3, units = "in", type = "windows", res = 400)
Box3_altmetric1 <- ggplot2::ggplot() + ggbeeswarm::geom_quasirandom(data = altmetrics2, ggplot2::aes(y = Altmetric.score, x = group, size = count), fill = "#1B9E77", col="#999999", alpha=0.8, shape = 21) + 
  ylim(0,300) +
  ggplot2::coord_flip() +
      ggplot2::theme_bw() +
      ggplot2::guides(fill = "none", colour = "none") +
      ggplot2::theme(legend.position= c(0, 1), legend.justification = c(0, 1)) +
      ggplot2::theme(legend.title = ggplot2::element_text(size = 9)) +
      ggplot2::theme(legend.direction="horizontal") +
      ggplot2::theme(legend.background = ggplot2::element_blank()) +
      ggplot2::labs(x = "Social media interest", y = "Altmetric score", size = latex2exp::TeX("Policy and patent citations")) +
      #ggplot2::theme(axis.ticks.y = element_blank()) + 
      ggplot2::theme(axis.text.y = ggplot2::element_text(size = 10, colour ="black",hjust = 0.5, angle = 0))

# add altmetrics and transnational info to an evidence map 
# load meta-analytic data
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv"))) 
altmetrics <- read.csv(here("Data","altmetrics.csv"))

# add altemtrics to the original data
dat <- dat %>% mutate(Altmetric.score = altmetrics$Altmetric.score, policy = altmetrics$Policy, patent = altmetrics$Patent)

dat <- dat[, c("Original paper journal", "Replication study fully completed", "Altmetric.score", "Paper #")]
names(dat) <- c("dimension1", "dimension2", "score", "study_id")
dat$score <- round(dat$score,0)

# delete the cases where the replications have not be conducted due to the lack of experimental protocol details
dat <- dat[!dat$dimension2 == "Not applicable",]

# run altmetric_aggregate function through each combination 
est_dat <- 
  dat %>%
  group_by(dimension1, dimension2) %>%
  group_modify(~ altmetric_aggregate(.x)) %>%
  ungroup()

est_dat1 <- est_dat

# policy and patent counts
dat <- suppressMessages(read_csv(here("Data","Timothy_2021.csv")))

# add altemtrics to the original data
dat <- dat %>% mutate(Altmetric.score = altmetrics$Altmetric.score, policy = altmetrics$Policy, patent = altmetrics$Patent)
dat <- dat %>% mutate(count = patent + policy)

dat <- dat[, c("Original paper journal", "Replication study fully completed", "count", "Paper #")]
names(dat) <- c("dimension1", "dimension2", "count", "study_id")
dat$count <- round(dat$count,0)

# delete the cases where the replications have not be conducted due to the lack of experimental protocol details
dat <- dat[!dat$dimension2 == "Not applicable",]

# run translation_aggregate function through each cell 
est_dat <- 
  dat %>%
  group_by(dimension1, dimension2) %>%
  group_modify(~ translation_aggregate(.x)) %>%
  ungroup()

est_dat2 <- est_dat

colnames(est_dat2)[colnames(est_dat2) == "estimate"] <- "count"
est_dat2 <- est_dat2[,1:3]

# combine
est_dat <- merge(est_dat1, est_dat2, by = c("dimension1", "dimension2"))
est_dat$count <- round(est_dat$count,1)

est_dat <- est_dat %>% mutate(dimension2 = case_when(dimension2 == "No replication"  ~ "Incomplete replication",
                                             dimension2 == "Full replication"  ~ "Full replication",
                                             dimension2 == "Partial replication"  ~ "Partial replication"))


#png(filename = "Box3_altmetric2.png", width = 6, height = 6, units = "in", type = "windows", res = 400)
Box3_altmetric2 <- ggplot(est_dat, aes(x = dimension1, y = dimension2, size = count, color = estimate)) +
  geom_point(alpha = 0.6) + 
  scale_color_gradient(
    low = "#E6AB02",
    high = "purple", 
    limits = c(0,400),
    guide = "colourbar") + 
  labs(x = "Dimension 1 (Journal)", y = " Dimension 2 (Replication completion)", color = "Altmetric score") +
  scale_size_identity() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  guides(size = "none") +
  theme(legend.position='top', 
        legend.justification='right',
        legend.direction='horizontal', 
        axis.text = element_text(color = "black"),
        axis.title = element_text(color = "black")) +
  geom_text(aes(label = as.character(count)), size = 2.5, color = "gray10", fontface = "bold") +
  labs(caption = "The value in the cell is the citation count of policies and patents") +
   theme(plot.caption = element_text(size = 8, color = "gray10", face = "italic"))

#png(filename = "Box3_altmetric.png", width = 5, height = 7, units = "in", type = "windows", res = 400)
plot_grid(Box3_altmetric1, Box3_altmetric2, labels = c('A','B'), label_size = 14, nrow = 2, ncol = 1, rel_heights = c(1,2)) 
```

# License  

This documented is licensed under the following license: [CC Attribution-Noncommercial-Share Alike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en).  

# Software and package versions  

```{r versions}
sessionInfo() %>% pander()
```

# References  